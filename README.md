# ALL-Cell-Classification
The proposed hybrid convolutional neural network architecture is a neural network architecture consisting of a combination of the VGG16, ResNet50, InceptionV3, and the DenseNet121 architectures, all of which have been pretrained on the ImageNet database. The purpose of this model is to identify if an image of a cell has acute lymphocytic leukemia (also referred to as ALL), or if it is a healthy cell. The dataset used contains 1700 images from the training set of the ALL Challenge dataset of ISBI 2019 (which is available here). Of those 1700 images, there were an equal number of images with healthy cells and images with ALL cells. 60% of those images were used to train the model, 20% of those images were used for the cross validation set, and 20% of those images were used for the test set. The model used in the study generally outperformed the VGG16, ResNet50, and the InceptionV3 models on the cross validation set, in which it achieved an accuracy of 92.35%, a sensitivity of 0.927, a specificity of 0.918, and an F1 score of 0.932. The goal of this study was to verify that the developed algorithm could be utilized by hospitals and doctors to better treat the thousands of people suffering with ALL across the world, many of whom are children.
