# ALL-Cell-Classification
  The proposed hybrid convolutional neural network architecture is a neural network architecture consisting of a combination of the VGG16, ResNet50, InceptionV3, and the DenseNet121 architectures, all of which have been pretrained on the ImageNet database. The purpose of this model is to identify if an image of a cell has acute lymphocytic leukemia (also referred to as ALL), or if it is a healthy cell. The dataset used contains 1700 images from the training set of the ALL Challenge dataset of ISBI 2019 (which is available here). Of those 1700 images, there were an equal number of images with healthy cells and images with ALL cells. 60% of those images were used to train the model, 20% of those images were used for the cross validation set, and 20% of those images were used for the test set. The model used in the project generally outperformed the VGG16, ResNet50, and the InceptionV3 models on the cross validation set, in which it achieved an accuracy of 92.35%, a sensitivity of 0.927, a specificity of 0.918, and an F1 score of 0.932. The goal of this project was to verify that the developed algorithm could be utilized by hospitals and doctors to better treat the thousands of people suffering with ALL across the world, many of whom are children.

# Proposed Model
  The proposed model for this task is a model architecture that is a hybrid of VGG16, ResNet50, InceptionV3, and DenseNet121. All of these model architectures are extremely powerful on their own, especially since theyâ€™ve already been pretrained on the ImageNet database. However, this task is extremely difficult because the ALL cells look almost identical to the healthy cells, and it is even more difficult in this case due to the relatively small number of images available to train the models on as a result of limitations on memory. In order to make a model with the ability to understand the subtle differences between the ALL cells and the healthy cells, a hybrid model that combines strengths of each model is proposed so that the hybrid model will be able to gain a broader understanding of the data and the differences between the ALL cells and the healthy cells. The model architecture is shown in the image below:
  ![alt text](https://github.com/rishipython/ALL-Cell-Classification/blob/main/proposedmodelarchitecture.png)

# Model Performance on Cross Validation Set
  Along with the proposed model architecture, three convolutional neural networks that are commonly used for computer vision tasks were constructed: VGG16, ResNet50, and InceptionV3. These models had their pretrained weights from training on the ImageNet database. The models were then trained on the training set using 33 epochs and a batch size of 10 to minimize their binary cross entropy loss on the training set. After the models were trained on the training set, they were evaluated on the cross validation set using four metrics: accuracy, sensitivity, specificity, AUC score, and F1 score.
  ![alt text](https://github.com/rishipython/ALL-Cell-Classification/blob/main/model_cross_validation_performance.png)
  As shown in the above table, the proposed model generally outperformed all of the other models, as it had the highest accuracy, the highest sensitivity, the second highest specificity, the second highest AUC score, and the highest F1 score.
  
# Proposed Model Performance on Test Set
  Now that the proposed model has been determined to have performed the best on the cross validation set, it will now be tested on the test set.
